{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn :: utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# sklearn :: models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# sklearn :: evaluation metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# convert scientific notation to decimals\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict length of flight delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = pd.read_csv('data/flightsmerged.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for flight Class (On_Time, Delayed, Cancelled)\n",
    "\n",
    "# Default value:\n",
    "df_flights['CLASS'] = 'On_Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Cancelled flights\n",
    "\n",
    "cancelled_flights = list(df_flights[df_flights['CANCELLED'] == 1].index)    \n",
    "df_flights.at[cancelled_flights, 'CLASS'] = 'Cancelled'\n",
    "    \n",
    "print(\"# Cancelled flights = \", len(df_flights[df_flights['CLASS'] == 'Cancelled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Delayed flights\n",
    "        \n",
    "delayed_flights = list(df_flights[(df_flights['DEPARTURE_DELAY'] !=0) | (df_flights['ARRIVAL_DELAY'] !=0)].index)    \n",
    "df_flights.at[delayed_flights, 'CLASS'] = 'Delayed'\n",
    "\n",
    "print(\"# Delayed flights = \", len(df_flights[df_flights['CLASS'] == 'Delayed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- On-time flights\n",
    "\n",
    "print(\"On-time flights = \",len(df_flights[df_flights['CLASS'] == 'On_Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_flights['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['Delay_sum']= df_flights['DEPARTURE_DELAY'].abs() + df_flights['ARRIVAL_DELAY'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['Average_delay']= df_flights.groupby['Delay_sum'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['Average_delay'] = df_flights['Average_delay'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_flights.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies\n",
    "\n",
    "categorical = 'CLASS'\n",
    "df_dummies = pd.get_dummies(df_flights[categorical])\n",
    "df_dummies.columns = [str(categorical)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_flights2 = pd.concat([df_flights, df_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "# Training The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the columns\n",
    "X_columns = ['CLASS_Delayed','CLASS_On_Time','CANCELLED']\n",
    "y_column = ['Average_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "\n",
    "threshold = 0.8\n",
    "X = df_flights2[X_columns]\n",
    "y = df_flights2[y_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1.0-threshold, shuffle=True)\n",
    "\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "# Testing The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn :: utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "models = [\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('RandomForestClassifier10', RandomForestClassifier(n_estimators=10)),\n",
    "    ('RandomForestClassifier100', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('KNeighborsClassifier9', KNeighborsClassifier(n_neighbors=9)),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier())\n",
    "]\n",
    "results = []\n",
    "for m in models:\n",
    "    print('MODEL', m[0])\n",
    "    model = m[1]\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)\n",
    "    results.append([m[0], precision, recall])\n",
    "    \n",
    "    # print top 5feature importance\n",
    "    importance = []\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print('Feature Importance')\n",
    "        importance = []\n",
    "        for i in range(len(X_columns)):\n",
    "            importance.append([X_columns[i], model.feature_importances_[i]])\n",
    "        print(pd.DataFrame(importance).sort_values(by=1, ascending=False).head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print('Feature Importance')\n",
    "        for i in range(len(X_columns)):\n",
    "            importance.append([X_columns[i], model.coef_[i]])\n",
    "        print(pd.DataFrame(importance).sort_values(by=1, ascending=False).head(10))\n",
    "        \n",
    "    print('')\n",
    "\n",
    "# sort the results and print as a table\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.columns = ['model', 'precision', 'recall']\n",
    "df_results = df_results.sort_values(by='precision', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = cohen_kappa_score(y_test, y_pred, weights ='quadratic')\n",
    "print('kappa', round(kappa, 4))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "results = []\n",
    "kf = KFold(n_splits=k)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred, weights ='quadratic')\n",
    "    results.append(round(kappa, 4))\n",
    "\n",
    "print('Kappa for each fold:', results)\n",
    "print('AVG(kappa)', round(np.mean(results), 4))\n",
    "print('STD(kappa)', round(np.std(results), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = [1 if x > i/10.0 else 0 for x in y_pred]\n",
    "    precision = precision_score(y_test, y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred,average='weighted')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
